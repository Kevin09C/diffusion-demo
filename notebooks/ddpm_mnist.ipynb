{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4f2046",
   "metadata": {},
   "source": [
    "# Denoising diffusion: MNIST\n",
    "\n",
    "The training of a DDPM for MNIST data can be launched by running the dedicated Python script in the parent folder. For using the default settings, without any custom modifications of the architecture or the training algorithm, simply run `python train_ddpm_mnist.py`. The training process may then be monitored via `tensorboard --logdir run/mnist/`. Subsequently, the final model is shortly tested in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e025d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "from diffusion import DDPM2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad292e1-9882-4871-af82-28ef890382a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = seed_everything(222222) # set random seeds manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7e6e76",
   "metadata": {},
   "source": [
    "## MNIST data\n",
    "\n",
    "First of all, let us import the validation data such that they can be easily accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = datasets.MNIST(\n",
    "    '../run/data/',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=32,\n",
    "    drop_last=False,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d262e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(val_loader))\n",
    "image_shape = x_batch.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e7721",
   "metadata": {},
   "source": [
    "We may also have a look at some of image samples from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(5, 5))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    image = x_batch[idx, 0].numpy()\n",
    "    ax.imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de1793",
   "metadata": {},
   "source": [
    "## DDPM import\n",
    "\n",
    "The DDPM with all its architectural hyperparameters and the learned weights is then initialized as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fa07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_file = '../run/mnist/version_0/checkpoints/last.ckpt'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "checkpoint = torch.load(ckpt_file, map_location=device)\n",
    "ddpm = DDPM2d.load_from_checkpoint(ckpt_file)\n",
    "\n",
    "ddpm = ddpm.eval()\n",
    "ddpm = ddpm.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b4792",
   "metadata": {},
   "source": [
    "For the sake of completeness, the used noise schedule is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2616dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = ddpm.betas.cpu().numpy()\n",
    "alphas_bar = ddpm.alphas_bar.cpu().numpy()\n",
    "log_snr = np.log(alphas_bar / (1 - alphas_bar))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(9, 2.5))\n",
    "\n",
    "ax1.plot(np.arange(len(betas)) + 1, betas, color=plt.cm.Set1(1))\n",
    "ax1.set(xlim=(0, len(ddpm.betas)), ylim=(0, ddpm.betas.max().item()))\n",
    "ax1.set(xlabel='t', ylabel='$\\\\beta$')\n",
    "ax1.grid(visible=True, which='both', color='gray', alpha=0.2, linestyle='-')\n",
    "ax1.set_axisbelow(True)\n",
    "\n",
    "ax2.plot(np.arange(len(alphas_bar)) + 1, np.sqrt(alphas_bar), color=plt.cm.Set1(2))\n",
    "ax2.set(xlim=(0, len(ddpm.alphas_bar)), ylim=(0, 1))\n",
    "ax2.set(xlabel='t', ylabel='$\\\\sqrt{\\\\bar{\\\\alpha}}$')\n",
    "ax2.grid(visible=True, which='both', color='gray', alpha=0.2, linestyle='-')\n",
    "ax2.set_axisbelow(True)\n",
    "\n",
    "ax3.plot(np.arange(len(log_snr)) + 1, log_snr, color=plt.cm.Set1(3))\n",
    "ax3.set(xlim=(0, len(ddpm.alphas_bar)))\n",
    "ax3.set(xlabel='t', ylabel='log-SNR')\n",
    "ax3.grid(visible=True, which='both', color='gray', alpha=0.2, linestyle='-')\n",
    "ax3.set_axisbelow(True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b933c00",
   "metadata": {},
   "source": [
    "Also the non-learnable component of the temporal embedding (of an arbitrary model layer) is visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinusoidal_encoding = ddpm.eps_model.encoder.first_conv.emb[0]\n",
    "tids = torch.arange(ddpm.num_steps).view(-1, 1)\n",
    "ts = tids + 1 # note that tidx = 0 corresponds to t = 1.0\n",
    "encs = sinusoidal_encoding(ts.to(device)).cpu()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "img = ax.imshow(encs.numpy(), cmap='PRGn', aspect='auto')\n",
    "ax.set(xlabel='embedding dim.', ylabel='time step')\n",
    "fig.colorbar(img)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db5c55",
   "metadata": {},
   "source": [
    "## Forward process\n",
    "\n",
    "Starting from an image sample, the forward diffusion gradually diffuses it into mere noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noisy = ddpm.diffuse_all_steps(x_batch.to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed85552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_steps = [0, 50, 100, 200, 500, 1000]\n",
    "\n",
    "sample_idx = np.random.randint(x_noisy.shape[1]) # select random sample from batch\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(plot_steps), figsize=(8, 2))\n",
    "for time_idx, ax in zip(plot_steps, axes.ravel()):\n",
    "    image = x_noisy[time_idx, sample_idx, 0].numpy()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title('{} steps'.format(time_idx))\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9dc2bb",
   "metadata": {},
   "source": [
    "## Generative process\n",
    "\n",
    "The reverse process generates new data by denoising pure random noise in stepwise fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e73990",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noise = torch.randn(16, *image_shape)\n",
    "x_denoise = ddpm.denoise_all_steps(x_noise.to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1487a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_steps_reverse = [ddpm.num_steps - s for s in reversed(plot_steps)]\n",
    "\n",
    "sample_idx = np.random.randint(x_denoise.shape[1]) # select random sample from batch\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(reverse_plot_steps), figsize=(8, 2))\n",
    "for time_idx, ax in zip(reverse_plot_steps, axes.ravel()):\n",
    "    image = x_denoise[time_idx, sample_idx, 0].numpy()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title('{} steps'.format(time_idx))\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb303cfa",
   "metadata": {},
   "source": [
    "An ensemble of images generated this way is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = ddpm.generate(sample_shape=image_shape, num_samples=25).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(5, 5))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    image = x_gen[idx, 0].numpy()\n",
    "    ax.imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef02e74",
   "metadata": {},
   "source": [
    "Not perfect, but also not so bad after all. There are certainly many opportunities for improvement. In this context, it would be helpful to better understand the relationship between the value of the loss function and the visual image quality in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
